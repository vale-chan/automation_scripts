{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schwellenwerte erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_BASE_FILE_PATH = \"\"  # input\n",
    "THRESHOLD_BASE_SHEET_NAME = \"\"  # input\n",
    "DEPARTMENT_INFORMATION_FILE_PATH = \"\"  # input\n",
    "DEPARTMENT_INFORMATION_SHEET_NAME = \"\"  # input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis_threshold = pd.read_excel(THRESHOLD_BASE_FILE_PATH, sheet_name=THRESHOLD_BASE_SHEET_NAME)\n",
    "df_basis_threshold = df_basis_threshold.astype(\"str\")\n",
    "# damit eval() funktioniert, musses en string si\n",
    "\n",
    "df_department_information = pd.read_excel(DEPARTMENT_INFORMATION_FILE_PATH, sheet_name=DEPARTMENT_INFORMATION_SHEET_NAME) #Versucht mit dem Sheet alle Abteilungen reinzubringen\n",
    "df_department_information = df_department_information.astype(\"str\")\n",
    "# damit .replace funktioniert, musses en string si\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments = df_department_information.department.drop_duplicates()\n",
    "\n",
    "dep_dict = {}\n",
    "for department in departments:\n",
    "    df_dep = df_department_information[df_department_information.department == department]\n",
    "    dep_dict[department] = dict(zip(df_dep[\"variable\"], df_dep[\"value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortiert nach inneren keys\n",
    "\n",
    "for key in dep_dict.keys():\n",
    "    new_d = {}\n",
    "    for k in sorted(dep_dict[key], key=len, reverse=True):\n",
    "        new_d[k] = dep_dict[key][k]\n",
    "    dep_dict[key] = new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresholds = df_basis_threshold\n",
    "\n",
    "for department in dep_dict:\n",
    "    df_thresholds[f\"{department}_threshold\"] = df_basis_threshold[\"base_threshold\"].replace(dep_dict[department], regex=True)\n",
    "\n",
    "df_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isevaluatable(s):\n",
    "    try:\n",
    "        eval(s)\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for department in dep_dict.keys():\n",
    "    for index, row in df_thresholds.iterrows():\n",
    "        s = str(row[f\"{department}_threshold\"])\n",
    "        if isevaluatable(s) == True:\n",
    "            df_thresholds.loc[index, f\"{department}_threshold\"] = eval(s)\n",
    "        else:\n",
    "            df_thresholds.loc[index, f\"{department}_threshold\"] = s\n",
    "\n",
    "df_thresholds.replace(\"nan\", np.NaN, inplace=True)\n",
    "\n",
    "df_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten-Tabelle erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten zusammenführen\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = \"\"  # input\n",
    "MERGED_DATA_FILE_PATH = \"\"  # input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA_FOLDER_PATH\n",
    "\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "file_list = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col=None, header=0)\n",
    "    file_list.append(df)\n",
    "\n",
    "df_collected_data = pd.concat(file_list, axis=0, ignore_index=True)\n",
    "df_collected_data = df_collected_data.drop(columns=[\"q_59\", \"q_63\"])\n",
    "\n",
    "\n",
    "df_collected_data.to_csv(MERGED_DATA_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfen, ob Fragen, welche nur 1 Antwort haben sollten, wirklich nur 1 Antwort haben\n",
    "\n",
    "one_value_list = [\"q_17\", \"q_30\", \"q_31\", \"q_32\", \"q_33\", \"q_34\", \"q_35\", \"q_36\", \"q_37\", \"q_38\", \"q_39\", \"q_40\", \"q_41\", \"q_42\", \"q_43\", \"q_44\", \"q_45\", \"q_46\", \"q_47\", \"q_48\", \"q_49\", \"q_50\", \"q_51\", \"q_52\", \"q_54\", \"q_71\", \"q_72\", \"q_73\", \"q_74\", \"q_75\", \"q_76\", \"q_77\", \"q_83\", \"q_84\", \"q_85\", \"q_86\", \"q_88\", \"q_89\", \"q_90\", \"q_91\", \"q_92\", \"q_93\", \"q_95\", \"q_97\", \"q_98\", \"q_99\", \"q_100\", \"q_102\", \"q_202\"]\n",
    "\n",
    "for item in one_value_list:\n",
    "    if item in df_collected_data.columns:\n",
    "        assert df_collected_data[item].count() == 1, f\"{item}: zu viele Antworten\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfen, ob alle Spalten mind. 1 Antwort enthalten\n",
    "\n",
    "for col in df_collected_data:\n",
    "    answers_count = df_collected_data[col].count()\n",
    "    assert answers_count > 0, f\"keine Antwort für Spalte {col}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ist-Werte Berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_FILE_PATH = \"\"  # input\n",
    "MAPPING_FILE_SHEET_NAME = \"\"  # input\n",
    "\n",
    "THRESHOLDS_FILE_PATH = \"\"  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(MERGED_DATA_FILE_PATH)\n",
    "df_mapping = pd.read_excel(MAPPING_FILE_PATH, sheet_name=MAPPING_FILE_SHEET_NAME)\n",
    "\n",
    "df_mapping\n",
    "\n",
    "# TO DO: hier vielleicht check einbauen, dass keine \"operation\" ein \"none\" ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vorlage ##\n",
    "\n",
    "# for sub_indicator in df_mapping[\"sub_id\"].drop_duplicates():\n",
    "#     q_ids = df_mapping.loc[df_mapping[\"sub_id\"] == sub_indicator, \"q_id\"].dropna()\n",
    "#     q_ids = q_ids[q_ids.isin(df_data.columns)]\n",
    "#     if len(q_ids) == 0:\n",
    "#         continue\n",
    "#     ops = df_mapping.loc[df_mapping[\"sub_id\"] == sub_indicator, \"operation\"].iloc[0] # der erste operator; z.B. wenn es mehrere q_id's hat, dann einfach der erste operator\n",
    "#     df = df_data.loc[:, q_ids]\n",
    "#     if ops == \"mean\":\n",
    "#         df = df.applymap(lambda x: x).mean().mean()\n",
    "#         print(sub_indicator, df)\n",
    "#     elif ops == \"sum\":\n",
    "#         df = df.applymap(lambda x: x).sum().sum()\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown operation {ops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresholds_values = df_thresholds\n",
    "values = {}\n",
    "\n",
    "for department in dep_dict.keys():\n",
    "    for sub_indicator in df_mapping[\"sub_id\"].drop_duplicates():\n",
    "        q_ids = df_mapping.loc[df_mapping[\"sub_id\"] == sub_indicator, \"q_id\"].dropna()\n",
    "        q_ids = q_ids[q_ids.isin(df_data.columns)]\n",
    "        if len(q_ids) == 0:\n",
    "            continue\n",
    "        ops = df_mapping.loc[df_mapping[\"sub_id\"] == sub_indicator, \"operation\"].iloc[0] # der erste operator; z.B. wenn es mehrere q_id's hat, dann einfach der erste operator\n",
    "        df = df_data.loc[df_data['q_500'] == department, q_ids]\n",
    "        if ops == \"mean\":\n",
    "            df = df.applymap(lambda x: x).mean().mean()\n",
    "            values[sub_indicator] = df\n",
    "        elif ops == \"sum\":\n",
    "            df = df.applymap(lambda x: x).sum().sum()\n",
    "            values[sub_indicator] = df\n",
    "        elif ops == 'none':\n",
    "            num_na = int(df.notna().sum())\n",
    "            if num_na == 0:\n",
    "               values[sub_indicator] = np.nan\n",
    "            elif num_na == 1:\n",
    "               values[sub_indicator] = df[df.notna()]\n",
    "            else:\n",
    "                raise ValueError(f\"There are more than 1 non-empty rows for column {q_ids}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown operation {ops}, {type(ops)}\")\n",
    "    df_thresholds_values[f\"{department}_value\"] = df_thresholds_values[\"sub_id\"].apply(lambda x: values.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresholds.to_csv(THRESHOLDS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schwellenwert mit Ist-Wert vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERFORMANCE_FILE_PATH = \"\"  # outupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = df_thresholds_values\n",
    "\n",
    "for department in dep_dict.keys():\n",
    "    df_performance[f\"{department}_performance\"] = \"\"\n",
    "\n",
    "    for index, row in df_performance.iterrows():\n",
    "        if row[f\"{department}_threshold\"] == np.nan:\n",
    "            continue\n",
    "        else:\n",
    "            if row[\"operator\"] == \">\":\n",
    "                if row[f\"{department}_value\"] > row[f\"{department}_threshold\"]:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = True\n",
    "                    # print(f\"{department}:> true\")\n",
    "                else:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = False\n",
    "                    # print(f\"{department}:> false\")\n",
    "            elif row[\"operator\"] == \">=\":\n",
    "                if row[f\"{department}_value\"] >= row[f\"{department}_threshold\"]:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = True\n",
    "                    # print(f\"{department}:>= true\")\n",
    "                else:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = False\n",
    "                    # print(f\"{department}:>= false\")\n",
    "            elif row[\"operator\"] == \"<\":\n",
    "                if row[f\"{department}_value\"] < row[f\"{department}_threshold\"]:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = True\n",
    "                    # print(f\"{department}:< true\")\n",
    "                else:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = False\n",
    "                    # print(f\"{department}:< false\")\n",
    "            elif row[\"operator\"] == \"<=\":\n",
    "                if row[f\"{department}_value\"] <= row[f\"{department}_threshold\"]:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = True\n",
    "                    # print(f\"{department}:<= true\")\n",
    "                else:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = False\n",
    "                    # print(f\"{department}:<= false\")\n",
    "            elif row[\"operator\"] == \"=\":\n",
    "                if row[f\"{department}_value\"] == row[f\"{department}_threshold\"]:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = True\n",
    "                    # print(f\"{department}:== true\")\n",
    "                else:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = False\n",
    "                    # print(f\"{department}:== false\")\n",
    "            elif row[\"operator\"] == \" =\":\n",
    "                if row[f\"{department}_value\"] == row[f\"{department}_threshold\"]:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = True\n",
    "                    # print(f\"{department}:== true\")\n",
    "                else:\n",
    "                    df_performance[f\"{department}_performance\"].loc[index] = False\n",
    "                    # print(f\"{department}: == false\")\n",
    "            elif row[\"operator\"] == \"status quo\":\n",
    "                df_performance[f\"{department}_performance\"].loc[index] = np.nan\n",
    "            elif row[\"operator\"] == \"nan\":\n",
    "                df_performance[f\"{department}_performance\"].loc[index] = np.nan\n",
    "            else:\n",
    "                print(f\"operator is not assigned: row {index}\")\n",
    "\n",
    "df_performance.to_csv(PERFORMANCE_FILE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
